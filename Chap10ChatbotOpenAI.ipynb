{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93569567",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To create an OpenAI API key:\n",
    "# https://beta.openai.com/signup/\n",
    "\n",
    "# This is using a Jupyter file. To download Python Jupyter:\n",
    "# https://jupyter.org/install.html\n",
    "\n",
    "# To install the OpenAI API using pip, you can use the following command in your terminal or command prompt:\n",
    "\n",
    "!pip install openai\n",
    "    \n",
    "# Or to force an upgrade of the OpenAI API to a specific version, you can run the following command in a terminal or command prompt:\n",
    "\n",
    "# pip install --upgrade openai==0.27.0\n",
    "\n",
    "\n",
    "# This command will install the OpenAI Python module, which provides a convenient way to interact with the OpenAI API using Python. The module includes functions for authenticating with the API using your API key, as well as functions for sending requests to the API and handling the responses.\n",
    "\n",
    "# Once you have installed the OpenAI module, you can import it into your Python script or Jupyter notebook and use it to access the full range of OpenAI's powerful AI models and tools.\n",
    "\n",
    "\n",
    "# The OpenAI documentation for their chat API. \n",
    "# https://platform.openai.com/docs/guides/chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6c6b0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what are the smallest countires within other countries in the world\n",
      "\n",
      "\n",
      "\n",
      "These are some of the smallest countries within other countries in the world:\n",
      "\n",
      "1. Campione d'Italia - an Italian enclave in Switzerland.\n",
      "2. Büsingen am Hochrhein - a German exclave entirely surrounded by Switzerland.\n",
      "3. Llívia - a Spanish town entirely surrounded by France.\n",
      "4. Point Roberts - a small unincorporated community that is part of the United States but physically located on the southern tip of a peninsula in Canada.\n",
      "5. Okinoshima - a Japanese island that is a UNESCO World Heritage site, located within the city of Munakata, Fukuoka Prefecture.\n",
      "\n",
      "Note that some of these examples, such as Campione d'Italia and Llívia, are not completely autonomous and are subject to the laws and regulations of the countries in which they are located.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import the openai module to access OpenAI's language models and other AI services through their API.\n",
    "# this simple code confirms you can access your api and get back responses\n",
    "import openai\n",
    "\n",
    "\n",
    "# Set your OpenAI API key\n",
    "openai.api_key = \"sk-************************\"\n",
    "\n",
    "# Define an initial conversation message from the chatbot\n",
    "conversation=[{\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}]\n",
    "\n",
    "# Start an infinite loop to keep the chatbot running until the user terminates the program\n",
    "while(True):\n",
    "    # Get input from the user\n",
    "    user_input = input(\"\")     \n",
    "    # Add the user's message to the conversation\n",
    "    conversation.append({\"role\": \"user\", \"content\": user_input})\n",
    "\n",
    "    # Use the GPT 3.5 turbo model to generate a response\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages = conversation\n",
    "    )\n",
    "\n",
    "    # Add the chatbot's response to the conversation\n",
    "    conversation.append({\"role\": \"assistant\", \"content\": response['choices'][0]['message']['content']})\n",
    "    # Print the chatbot's response to the console\n",
    "    print(\"\\n\" + response['choices'][0]['message']['content'] + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2c972c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7871\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7871/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import openai\n",
    "import gradio as gr\n",
    "\n",
    "# Set your OpenAI API key\n",
    "openai.api_key = \"sk-**************************\"\n",
    "\n",
    "# Define an initial conversation message from the chatbot\n",
    "conversation = [{\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}]\n",
    "\n",
    "# Define the chatbot response function\n",
    "def chatbot_response(user_input):\n",
    "    global conversation  # Access the global conversation variable\n",
    "    \n",
    "    # Append the user's input to the conversation\n",
    "    conversation.append({\"role\": \"user\", \"content\": user_input})\n",
    "\n",
    "    # Generate a response from GPT-3.5-turbo using OpenAI API\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=conversation\n",
    "    )\n",
    "\n",
    "    # Extract the assistant's response from the API result\n",
    "    assistant_response = response['choices'][0]['message']['content']\n",
    "    \n",
    "    # Append the assistant's response to the conversation\n",
    "    conversation.append({\"role\": \"assistant\", \"content\": assistant_response})\n",
    "\n",
    "    # Return the assistant's response\n",
    "    return assistant_response\n",
    "\n",
    "# Create a Gradio interface for the chatbot response function\n",
    "GUI = gr.Interface(fn=chatbot_response,\n",
    "                   inputs=\"text\",\n",
    "                   outputs=\"text\",\n",
    "                   title=\"ChatBot-Turbo\",\n",
    "                   description=\"This is a chatbot using OpenAI's GPT-3.5-turbo model. Enter your message and get a response.\")\n",
    "\n",
    "# Launch the Gradio interface\n",
    "GUI.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "decbcb38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7873\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7873/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import openai\n",
    "import gradio as gr\n",
    "import json\n",
    "\n",
    "# Set your OpenAI API key\n",
    "openai.api_key = \"sk-**************************\"\n",
    "\n",
    "# Define an initial conversation message from the chatbot\n",
    "conversation = [{\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}]\n",
    "\n",
    "# Define the chatbot response function\n",
    "def chatbot_response(user_input):\n",
    "    global conversation\n",
    "    conversation.append({\"role\": \"user\", \"content\": user_input})\n",
    "\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=conversation\n",
    "    )\n",
    "\n",
    "    assistant_response = response['choices'][0]['message']['content']\n",
    "    conversation.append({\"role\": \"assistant\", \"content\": assistant_response})\n",
    "    \n",
    "    \n",
    "    # Save conversation history to file\n",
    "    with open(\"conversation_history.json\", \"w\") as file:\n",
    "        json.dump(conversation, file)\n",
    "\n",
    "    # Return the assistant's response\n",
    "    return assistant_response\n",
    "\n",
    "# Create a Gradio interface for the chatbot response function\n",
    "GUI = gr.Interface(fn=chatbot_response,\n",
    "                   inputs=\"text\",\n",
    "                   outputs=\"text\",\n",
    "                   title=\"ChatBot-Turbo\",\n",
    "                   description=\"This is a chatbot using OpenAI's GPT-3.5-turbo model. Enter your message and get a response.\")\n",
    "\n",
    "# Launch the Gradio interface\n",
    "GUI.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd2d084",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
